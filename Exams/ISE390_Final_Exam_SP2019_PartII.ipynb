{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISE390\n",
    "## Data Science\n",
    "### Final exam Part II\n",
    "### Time: 50 minutes\n",
    "\n",
    "\n",
    "\n",
    "You are given 70,000 images (each image consists of 28*28 pixels) of hand-written digits from 0-9.\n",
    "The task is to design a classifier that can recognize these images. In other words, you input an image from this dataset and the output is a predicted number from 0 to 9.\n",
    "\n",
    "For this problem, we only focus on classification task between two digits: 3, and 8 in one round and 5 and 6 in the other round, meaning that you deal with a binary classification task. \n",
    "\n",
    "\n",
    "The dataset contains 60,000 images for training and 10,000 for test. \n",
    "Do the following:\n",
    "1. Extract all images contaning digits 3 and 8 both in training and test data set.\n",
    "2.\tPlot an image of digit 3 from training data. It could be any image of digit 3.\n",
    "3.\tTrain a feedforward neural network with the following architecture: \n",
    "    - Three layers\n",
    "    -\t256 hidden units\n",
    "    -\tfeedforward\n",
    "    -   number of epoch = 10\n",
    "4.\tPrint out the accuracy of your model for each epoch both for the test and train sets\n",
    "5.\tReport the results in terms of a confusion matrix\n",
    "6.\tRepeat step 3,4,and 5 but with 25 hidden units\n",
    "7.\tRepeat  1-6 with input images 5 and 6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get indices of all the 3 and 8 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_train_3and8 = np.where((y_train == 3) | (y_train == 8))\n",
    "indices_test_3and8 = np.where((y_test == 3) | (y_test == 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Extract the 3 and 8 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11982,)\n",
      "(1984,)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array(x_train)[indices_train_3and8]\n",
    "y_train = np.array(y_train)[indices_train_3and8]\n",
    "\n",
    "x_test = np.array(x_test)[indices_test_3and8]\n",
    "y_test = np.array(y_test)[indices_test_3and8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Plot an image of digit 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_vector_size = 28*28\n",
    "x_train = x_train.reshape(x_train.shape[0], image_vector_size)\n",
    "x_test = x_test.reshape(x_test.shape[0], image_vector_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to set values to either 0 or 1, other wise the index error occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "y_train[y_train == 3] = 0\n",
    "y_train[y_train == 8] = 1\n",
    "y_test[y_test == 3] = 0\n",
    "y_test[y_test == 8] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train a feedforward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, train accuracy = 82.77%, test accuracy = 82.81%\n",
      "Epoch = 2, train accuracy = 59.71%, test accuracy = 57.21%\n",
      "Epoch = 3, train accuracy = 62.59%, test accuracy = 61.64%\n",
      "Epoch = 4, train accuracy = 78.95%, test accuracy = 80.59%\n",
      "Epoch = 5, train accuracy = 57.60%, test accuracy = 56.30%\n",
      "Epoch = 6, train accuracy = 77.37%, test accuracy = 79.33%\n",
      "Epoch = 7, train accuracy = 70.67%, test accuracy = 72.88%\n",
      "Epoch = 8, train accuracy = 59.98%, test accuracy = 58.01%\n",
      "Epoch = 9, train accuracy = 79.78%, test accuracy = 81.10%\n",
      "Epoch = 10, train accuracy = 54.16%, test accuracy = 53.48%\n"
     ]
    }
   ],
   "source": [
    "# Implementation of a simple MLP network with one hidden layer. Tested on the iris data set.\n",
    "# Requires: numpy, sklearn>=0.18.1, tensorflow>=1.0\n",
    "\n",
    "# NOTE: In order to make the code simple, we rewrite x * W_1 + b_1 = x' * W_1'\n",
    "# where x' = [x | 1] and W_1' is the matrix W_1 appended with a new row with elements b_1's.\n",
    "# Similarly, for h * W_2 + b_2\n",
    "\n",
    "# author :vinhkhuc  Feb 26, 2017\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "def init_weights(shape):\n",
    "    \"\"\" Weight initialization \"\"\"\n",
    "    weights = tf.random_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(weights)\n",
    "\n",
    "def forwardprop(X, w_1, w_2):\n",
    "    \"\"\"\n",
    "    Forward-propagation.\n",
    "    IMPORTANT: yhat is not softmax since TensorFlow's softmax_cross_entropy_with_logits() does that internally.\n",
    "    \"\"\"\n",
    "    h    = tf.nn.sigmoid(tf.matmul(X, w_1))  # The \\sigma function\n",
    "    yhat = tf.matmul(h, w_2)  # The \\varphi function\n",
    "    return yhat\n",
    "\n",
    "def get_data(data, target):\n",
    "    \"\"\" Read the iris data set and split them into training and test sets \"\"\"\n",
    "    \n",
    "    # Prepend the column of 1s for bias\n",
    "    N, M = data.shape\n",
    "    all_X = np.ones((N, M + 1))\n",
    "    all_X[:, 1:] = data\n",
    "\n",
    "    # Convert into one-hot vectors\n",
    "    num_labels = len(np.unique(target)) # needs to be nine since the options are 3 and 8, not 0 and 1\n",
    "    all_Y = np.eye(num_labels)[target]\n",
    "    return all_X, all_Y\n",
    "\n",
    "def main():\n",
    "    train_X, train_y = get_data(x_train, y_train)\n",
    "    test_X, test_y = get_data(x_test, y_test)\n",
    "\n",
    "    # Layer's sizes\n",
    "    x_size = train_X.shape[1]   # Number of input nodes: 4 features and 1 bias\n",
    "    h_size = 256                # Number of hidden nodes\n",
    "    y_size = train_y.shape[1]   # Number of outcomes (3 iris flowers)\n",
    "\n",
    "    # Symbols\n",
    "    X = tf.placeholder(\"float\", shape=[None, x_size])\n",
    "    y = tf.placeholder(\"float\", shape=[None, y_size])\n",
    "\n",
    "    # Weight initializations\n",
    "    w_1 = init_weights((x_size, h_size))\n",
    "    w_2 = init_weights((h_size, y_size))\n",
    "\n",
    "    # Forward propagation\n",
    "    yhat    = forwardprop(X, w_1, w_2)\n",
    "    predict = tf.argmax(yhat, axis=1)\n",
    "\n",
    "    # Backward propagation\n",
    "    cost    = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=yhat))\n",
    "    updates = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "\n",
    "    # Run SGD\n",
    "    sess = tf.Session()\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(10):\n",
    "        # Train with each example\n",
    "        for i in range(len(train_X)):\n",
    "            sess.run(updates, feed_dict={X: train_X[i: i + 1], y: train_y[i: i + 1]})\n",
    "\n",
    "        train_accuracy = np.mean(np.argmax(train_y, axis=1) ==\n",
    "                                 sess.run(predict, feed_dict={X: train_X, y: train_y}))\n",
    "        test_accuracy  = np.mean(np.argmax(test_y, axis=1) ==\n",
    "                                 sess.run(predict, feed_dict={X: test_X, y: test_y}))\n",
    "\n",
    "        print(\"Epoch = %d, train accuracy = %.2f%%, test accuracy = %.2f%%\"\n",
    "              % (epoch + 1, 100. * train_accuracy, 100. * test_accuracy))\n",
    "\n",
    "    sess.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Repeat with 25 hidden units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, train accuracy = 93.30%, test accuracy = 92.65%\n",
      "Epoch = 2, train accuracy = 68.48%, test accuracy = 69.46%\n",
      "Epoch = 3, train accuracy = 76.09%, test accuracy = 77.03%\n",
      "Epoch = 4, train accuracy = 91.47%, test accuracy = 91.78%\n",
      "Epoch = 5, train accuracy = 52.55%, test accuracy = 52.05%\n",
      "Epoch = 6, train accuracy = 74.97%, test accuracy = 78.70%\n",
      "Epoch = 7, train accuracy = 90.30%, test accuracy = 90.27%\n",
      "Epoch = 8, train accuracy = 92.08%, test accuracy = 91.89%\n",
      "Epoch = 9, train accuracy = 91.40%, test accuracy = 91.19%\n",
      "Epoch = 10, train accuracy = 91.99%, test accuracy = 91.73%\n"
     ]
    }
   ],
   "source": [
    "# Implementation of a simple MLP network with one hidden layer. Tested on the iris data set.\n",
    "# Requires: numpy, sklearn>=0.18.1, tensorflow>=1.0\n",
    "\n",
    "# NOTE: In order to make the code simple, we rewrite x * W_1 + b_1 = x' * W_1'\n",
    "# where x' = [x | 1] and W_1' is the matrix W_1 appended with a new row with elements b_1's.\n",
    "# Similarly, for h * W_2 + b_2\n",
    "\n",
    "# author :vinhkhuc  Feb 26, 2017\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "def init_weights(shape):\n",
    "    \"\"\" Weight initialization \"\"\"\n",
    "    weights = tf.random_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(weights)\n",
    "\n",
    "def forwardprop(X, w_1, w_2):\n",
    "    \"\"\"\n",
    "    Forward-propagation.\n",
    "    IMPORTANT: yhat is not softmax since TensorFlow's softmax_cross_entropy_with_logits() does that internally.\n",
    "    \"\"\"\n",
    "    h    = tf.nn.sigmoid(tf.matmul(X, w_1))  # The \\sigma function\n",
    "    yhat = tf.matmul(h, w_2)  # The \\varphi function\n",
    "    return yhat\n",
    "\n",
    "def get_data(data, target):\n",
    "    \"\"\" Read the iris data set and split them into training and test sets \"\"\"\n",
    "    \n",
    "    # Prepend the column of 1s for bias\n",
    "    N, M = data.shape\n",
    "    all_X = np.ones((N, M + 1))\n",
    "    all_X[:, 1:] = data\n",
    "\n",
    "    # Convert into one-hot vectors\n",
    "    num_labels = len(np.unique(target))\n",
    "    all_Y = np.eye(num_labels)[target]\n",
    "    return all_X, all_Y\n",
    "\n",
    "def main():\n",
    "    train_X, train_y = get_data(x_train, y_train)\n",
    "    test_X, test_y = get_data(x_test, y_test)\n",
    "\n",
    "    # Layer's sizes\n",
    "    x_size = train_X.shape[1]   # Number of input nodes: 4 features and 1 bias\n",
    "    h_size = 25                 # Number of hidden units\n",
    "    y_size = train_y.shape[1]   # Number of outcomes (3 iris flowers)\n",
    "\n",
    "    # Symbols\n",
    "    X = tf.placeholder(\"float\", shape=[None, x_size])\n",
    "    y = tf.placeholder(\"float\", shape=[None, y_size])\n",
    "\n",
    "    # Weight initializations\n",
    "    w_1 = init_weights((x_size, h_size))\n",
    "    w_2 = init_weights((h_size, y_size))\n",
    "\n",
    "    # Forward propagation\n",
    "    yhat    = forwardprop(X, w_1, w_2)\n",
    "    predict = tf.argmax(yhat, axis=1)\n",
    "\n",
    "    # Backward propagation\n",
    "    cost    = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=yhat))\n",
    "    updates = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "\n",
    "    # Run SGD\n",
    "    sess = tf.Session()\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(10):\n",
    "        # Train with each example\n",
    "        for i in range(len(train_X)):\n",
    "            sess.run(updates, feed_dict={X: train_X[i: i + 1], y: train_y[i: i + 1]})\n",
    "\n",
    "        train_accuracy = np.mean(np.argmax(train_y, axis=1) ==\n",
    "                                 sess.run(predict, feed_dict={X: train_X, y: train_y}))\n",
    "        test_accuracy  = np.mean(np.argmax(test_y, axis=1) ==\n",
    "                                 sess.run(predict, feed_dict={X: test_X, y: test_y}))\n",
    "\n",
    "        print(\"Epoch = %d, train accuracy = %.2f%%, test accuracy = %.2f%%\"\n",
    "              % (epoch + 1, 100. * train_accuracy, 100. * test_accuracy))\n",
    "\n",
    "    sess.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Repeat all steps for 5 and 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "indices_train = np.where((y_train == 5) | (y_train == 6))\n",
    "indices_test = np.where((y_test == 5) | (y_test == 6))\n",
    "\n",
    "x_train = np.array(x_train)[indices_train]\n",
    "y_train = np.array(y_train)[indices_train]\n",
    "\n",
    "x_test = np.array(x_test)[indices_test]\n",
    "y_test = np.array(y_test)[indices_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_vector_size = 28*28\n",
    "x_train = x_train.reshape(x_train.shape[0], image_vector_size)\n",
    "x_test = x_test.reshape(x_test.shape[0], image_vector_size)\n",
    "\n",
    "y_train[y_train == 5] = 0\n",
    "y_train[y_train == 6] = 1\n",
    "y_test[y_test == 5] = 0\n",
    "y_test[y_test == 6] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, train accuracy = 94.01%, test accuracy = 94.11%\n",
      "Epoch = 2, train accuracy = 94.68%, test accuracy = 94.92%\n",
      "Epoch = 3, train accuracy = 94.83%, test accuracy = 94.32%\n",
      "Epoch = 4, train accuracy = 94.23%, test accuracy = 94.65%\n",
      "Epoch = 5, train accuracy = 93.21%, test accuracy = 92.97%\n",
      "Epoch = 6, train accuracy = 90.41%, test accuracy = 91.03%\n",
      "Epoch = 7, train accuracy = 90.91%, test accuracy = 90.32%\n",
      "Epoch = 8, train accuracy = 60.46%, test accuracy = 59.24%\n",
      "Epoch = 9, train accuracy = 72.70%, test accuracy = 72.54%\n",
      "Epoch = 10, train accuracy = 60.43%, test accuracy = 59.03%\n"
     ]
    }
   ],
   "source": [
    "# Implementation of a simple MLP network with one hidden layer. Tested on the iris data set.\n",
    "# Requires: numpy, sklearn>=0.18.1, tensorflow>=1.0\n",
    "\n",
    "# NOTE: In order to make the code simple, we rewrite x * W_1 + b_1 = x' * W_1'\n",
    "# where x' = [x | 1] and W_1' is the matrix W_1 appended with a new row with elements b_1's.\n",
    "# Similarly, for h * W_2 + b_2\n",
    "\n",
    "# author :vinhkhuc  Feb 26, 2017\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "def init_weights(shape):\n",
    "    \"\"\" Weight initialization \"\"\"\n",
    "    weights = tf.random_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(weights)\n",
    "\n",
    "def forwardprop(X, w_1, w_2):\n",
    "    \"\"\"\n",
    "    Forward-propagation.\n",
    "    IMPORTANT: yhat is not softmax since TensorFlow's softmax_cross_entropy_with_logits() does that internally.\n",
    "    \"\"\"\n",
    "    h    = tf.nn.sigmoid(tf.matmul(X, w_1))  # The \\sigma function\n",
    "    yhat = tf.matmul(h, w_2)  # The \\varphi function\n",
    "    return yhat\n",
    "\n",
    "def get_data(data, target):\n",
    "    \"\"\" Read the iris data set and split them into training and test sets \"\"\"\n",
    "    \n",
    "    # Prepend the column of 1s for bias\n",
    "    N, M = data.shape\n",
    "    all_X = np.ones((N, M + 1))\n",
    "    all_X[:, 1:] = data\n",
    "\n",
    "    # Convert into one-hot vectors\n",
    "    num_labels = len(np.unique(target)) # needs to be nine since the options are 3 and 8, not 0 and 1\n",
    "    all_Y = np.eye(num_labels)[target]\n",
    "    return all_X, all_Y\n",
    "\n",
    "def main():\n",
    "    train_X, train_y = get_data(x_train, y_train)\n",
    "    test_X, test_y = get_data(x_test, y_test)\n",
    "\n",
    "    # Layer's sizes\n",
    "    x_size = train_X.shape[1]   # Number of input nodes: 4 features and 1 bias\n",
    "    h_size = 256                # Number of hidden nodes\n",
    "    y_size = train_y.shape[1]   # Number of outcomes (3 iris flowers)\n",
    "\n",
    "    # Symbols\n",
    "    X = tf.placeholder(\"float\", shape=[None, x_size])\n",
    "    y = tf.placeholder(\"float\", shape=[None, y_size])\n",
    "\n",
    "    # Weight initializations\n",
    "    w_1 = init_weights((x_size, h_size))\n",
    "    w_2 = init_weights((h_size, y_size))\n",
    "\n",
    "    # Forward propagation\n",
    "    yhat    = forwardprop(X, w_1, w_2)\n",
    "    predict = tf.argmax(yhat, axis=1)\n",
    "\n",
    "    # Backward propagation\n",
    "    cost    = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=yhat))\n",
    "    updates = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "\n",
    "    # Run SGD\n",
    "    sess = tf.Session()\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(10):\n",
    "        # Train with each example\n",
    "        for i in range(len(train_X)):\n",
    "            sess.run(updates, feed_dict={X: train_X[i: i + 1], y: train_y[i: i + 1]})\n",
    "\n",
    "        train_accuracy = np.mean(np.argmax(train_y, axis=1) ==\n",
    "                                 sess.run(predict, feed_dict={X: train_X, y: train_y}))\n",
    "        test_accuracy  = np.mean(np.argmax(test_y, axis=1) ==\n",
    "                                 sess.run(predict, feed_dict={X: test_X, y: test_y}))\n",
    "\n",
    "        print(\"Epoch = %d, train accuracy = %.2f%%, test accuracy = %.2f%%\"\n",
    "              % (epoch + 1, 100. * train_accuracy, 100. * test_accuracy))\n",
    "\n",
    "    sess.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, train accuracy = 80.22%, test accuracy = 80.59%\n",
      "Epoch = 2, train accuracy = 88.21%, test accuracy = 87.14%\n",
      "Epoch = 3, train accuracy = 87.73%, test accuracy = 87.95%\n",
      "Epoch = 4, train accuracy = 84.06%, test accuracy = 83.51%\n",
      "Epoch = 5, train accuracy = 92.22%, test accuracy = 92.32%\n",
      "Epoch = 6, train accuracy = 92.49%, test accuracy = 92.54%\n",
      "Epoch = 7, train accuracy = 90.68%, test accuracy = 90.65%\n",
      "Epoch = 8, train accuracy = 93.92%, test accuracy = 93.41%\n",
      "Epoch = 9, train accuracy = 94.70%, test accuracy = 94.54%\n",
      "Epoch = 10, train accuracy = 93.67%, test accuracy = 93.30%\n"
     ]
    }
   ],
   "source": [
    "# Implementation of a simple MLP network with one hidden layer. Tested on the iris data set.\n",
    "# Requires: numpy, sklearn>=0.18.1, tensorflow>=1.0\n",
    "\n",
    "# NOTE: In order to make the code simple, we rewrite x * W_1 + b_1 = x' * W_1'\n",
    "# where x' = [x | 1] and W_1' is the matrix W_1 appended with a new row with elements b_1's.\n",
    "# Similarly, for h * W_2 + b_2\n",
    "\n",
    "# author :vinhkhuc  Feb 26, 2017\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "def init_weights(shape):\n",
    "    \"\"\" Weight initialization \"\"\"\n",
    "    weights = tf.random_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(weights)\n",
    "\n",
    "def forwardprop(X, w_1, w_2):\n",
    "    \"\"\"\n",
    "    Forward-propagation.\n",
    "    IMPORTANT: yhat is not softmax since TensorFlow's softmax_cross_entropy_with_logits() does that internally.\n",
    "    \"\"\"\n",
    "    h    = tf.nn.sigmoid(tf.matmul(X, w_1))  # The \\sigma function\n",
    "    yhat = tf.matmul(h, w_2)  # The \\varphi function\n",
    "    return yhat\n",
    "\n",
    "def get_data(data, target):\n",
    "    \"\"\" Read the iris data set and split them into training and test sets \"\"\"\n",
    "    \n",
    "    # Prepend the column of 1s for bias\n",
    "    N, M = data.shape\n",
    "    all_X = np.ones((N, M + 1))\n",
    "    all_X[:, 1:] = data\n",
    "\n",
    "    # Convert into one-hot vectors\n",
    "    num_labels = len(np.unique(target))\n",
    "    all_Y = np.eye(num_labels)[target]\n",
    "    return all_X, all_Y\n",
    "\n",
    "def main():\n",
    "    train_X, train_y = get_data(x_train, y_train)\n",
    "    test_X, test_y = get_data(x_test, y_test)\n",
    "\n",
    "    # Layer's sizes\n",
    "    x_size = train_X.shape[1]   # Number of input nodes: 4 features and 1 bias\n",
    "    h_size = 25                 # Number of hidden units\n",
    "    y_size = train_y.shape[1]   # Number of outcomes (3 iris flowers)\n",
    "\n",
    "    # Symbols\n",
    "    X = tf.placeholder(\"float\", shape=[None, x_size])\n",
    "    y = tf.placeholder(\"float\", shape=[None, y_size])\n",
    "\n",
    "    # Weight initializations\n",
    "    w_1 = init_weights((x_size, h_size))\n",
    "    w_2 = init_weights((h_size, y_size))\n",
    "\n",
    "    # Forward propagation\n",
    "    yhat    = forwardprop(X, w_1, w_2)\n",
    "    predict = tf.argmax(yhat, axis=1)\n",
    "\n",
    "    # Backward propagation\n",
    "    cost    = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=yhat))\n",
    "    updates = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "\n",
    "    # Run SGD\n",
    "    sess = tf.Session()\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(10):\n",
    "        # Train with each example\n",
    "        for i in range(len(train_X)):\n",
    "            sess.run(updates, feed_dict={X: train_X[i: i + 1], y: train_y[i: i + 1]})\n",
    "\n",
    "        train_accuracy = np.mean(np.argmax(train_y, axis=1) ==\n",
    "                                 sess.run(predict, feed_dict={X: train_X, y: train_y}))\n",
    "        test_accuracy  = np.mean(np.argmax(test_y, axis=1) ==\n",
    "                                 sess.run(predict, feed_dict={X: test_X, y: test_y}))\n",
    "\n",
    "        print(\"Epoch = %d, train accuracy = %.2f%%, test accuracy = %.2f%%\"\n",
    "              % (epoch + 1, 100. * train_accuracy, 100. * test_accuracy))\n",
    "\n",
    "    sess.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
