{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load each of the speaker files\n",
    "Librosa loads in the speaker files that were premade for each individual speaker. It returns two values, the series of audio data for each speaker, and the sample rate for each speaker. The sample rate was set to 8 KHz as an argument for the function. We now have a matrix for each individual speaker, labeled by letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "a, sr = librosa.load('/Users/James/Documents/SBU/ISE390/SpeechProject/Audio/ConcatenatedAudio/speaker1.wav', sr=8000)\n",
    "b, sr = librosa.load('/Users/James/Documents/SBU/ISE390/SpeechProject/Audio/ConcatenatedAudio/speaker2.wav', sr=8000)\n",
    "c, sr = librosa.load('/Users/James/Documents/SBU/ISE390/SpeechProject/Audio/ConcatenatedAudio/speaker3.wav', sr=8000)\n",
    "d, sr = librosa.load('/Users/James/Documents/SBU/ISE390/SpeechProject/Audio/ConcatenatedAudio/speaker4.wav', sr=8000)\n",
    "e, sr = librosa.load('/Users/James/Documents/SBU/ISE390/SpeechProject/Audio/ConcatenatedAudio/speaker5.wav', sr=8000)\n",
    "f, sr = librosa.load('/Users/James/Documents/SBU/ISE390/SpeechProject/Audio/ConcatenatedAudio/speaker6.wav', sr=8000)\n",
    "g, sr = librosa.load('/Users/James/Documents/SBU/ISE390/SpeechProject/Audio/ConcatenatedAudio/speaker7.wav', sr=8000)\n",
    "h, sr = librosa.load('/Users/James/Documents/SBU/ISE390/SpeechProject/Audio/ConcatenatedAudio/speaker8.wav', sr=8000)\n",
    "i, sr = librosa.load('/Users/James/Documents/SBU/ISE390/SpeechProject/Audio/ConcatenatedAudio/speaker9.wav', sr=8000)\n",
    "j, sr = librosa.load('/Users/James/Documents/SBU/ISE390/SpeechProject/Audio/ConcatenatedAudio/speaker10.wav', sr=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take the log of the absolute value of the fourier transform, segmented into 20 ms windows with 10ms overlap\n",
    "Librosa's stft function takes the short time fourier transform of the series of audio data that is provided as an argument. Since the sample rate for these series' is 8 KHz, that means that 160 samples would be 20 ms and 80 samples would be 10 ms. Set the argument n_fft = 160 so that the window size that is returned in a matrix is 20 ms and then hop_length is set to 10 ms so that there is also an overlap of 10 ms for each window that is selected. We get a new matrix for each speaker doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.log(np.abs(librosa.stft(a, n_fft=160,hop_length=80)))\n",
    "B = np.log(np.abs(librosa.stft(b, n_fft=160,hop_length=80)))\n",
    "C = np.log(np.abs(librosa.stft(c, n_fft=160,hop_length=80)))\n",
    "D = np.log(np.abs(librosa.stft(d, n_fft=160,hop_length=80)))\n",
    "E = np.log(np.abs(librosa.stft(e, n_fft=160,hop_length=80)))\n",
    "F = np.log(np.abs(librosa.stft(f, n_fft=160,hop_length=80)))\n",
    "G = np.log(np.abs(librosa.stft(g, n_fft=160,hop_length=80)))\n",
    "H = np.log(np.abs(librosa.stft(h, n_fft=160,hop_length=80)))\n",
    "I = np.log(np.abs(librosa.stft(i, n_fft=160,hop_length=80)))\n",
    "J = np.log(np.abs(librosa.stft(j, n_fft=160,hop_length=80)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the shape of each speaker's matrix\n",
    "This returns the shape of each of the speakers' individual matrix. We use this to figure out the smallest one so that we can later resize each of the matrices to the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 21461) (81, 15085) (81, 14297) (81, 18885) (81, 16497) (81, 22005) (81, 23833) (81, 23081) (81, 19637) (81, 29009)\n"
     ]
    }
   ],
   "source": [
    "print(A.shape, B.shape, C.shape, D.shape, E.shape, F.shape, G.shape, H.shape, I.shape, J.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize each matrix so that they are all the same size\n",
    "This slices each of the matrices so that they are all the same length (amount of windows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = A[:, :14297]\n",
    "B = B[:, :14297]\n",
    "C = C[:, :14297]\n",
    "D = D[:, :14297]\n",
    "E = E[:, :14297]\n",
    "F = F[:, :14297]\n",
    "G = G[:, :14297]\n",
    "H = H[:, :14297]\n",
    "I = I[:, :14297]\n",
    "J = J[:, :14297]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the target array of ID's for each speaker\n",
    "Each window should be labeled to the speaker it is from. To do this, we set an array named target. Since there are 14,297 windows for each speaker, we set that many target labels in an array to match that. The size should be the same as the amount of windows x the amount of speakers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.array(np.zeros(shape=(142970,)))\n",
    "target[0 : 14297] = 0\n",
    "target[14297 :28594] = 1\n",
    "target[28594 :42891] = 2\n",
    "target[42891 :57188] = 3\n",
    "target[57188 :71485] = 4\n",
    "target[71485 :85782] = 5\n",
    "target[85782 :100079] = 6\n",
    "target[100079 :114376] = 7\n",
    "target[114376 :128673] = 8\n",
    "target[128673 :142970] = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate the transpose of each of the matrices so that the shape matches the target value matrix shape\n",
    "We then need to take the transpose of each of these matrices, since they are not the correct shape initially. We then concatenate each of these transposed matrices into one larger matrix named \"data\". This is the matrix that is going to be fed into the neural network, along with the target array of labels. I also made sure to set the data type of the target array to integers, as the data would not be compatible otherwise with the neural network algorithm. Then, to make sure that they fit with each other and are the same size, we print both of the shapes of the matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size:  (142970, 81) \n",
      "Target shape:  (142970,)\n"
     ]
    }
   ],
   "source": [
    "data = np.concatenate([A.T ,B.T, C.T, D.T, E.T, F.T, G.T, H.T, I.T, J.T])\n",
    "target = target.astype(int)\n",
    "print(\"Data size: \", data.shape, \"\\nTarget shape: \", target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the neural network and return the accuracy results\n",
    "There are several steps involved in using the neural network to predict speakers. \n",
    "\n",
    "First, the data is fed in using the get_data() function. This uses the data and creates the one hot vectors that are needed. It then returns the data into 4 different values, a training and test set for both the data and the target values. 90% is assigned as training data, and 10% as test data.\n",
    "\n",
    "Once this is done, the size of the input, output, and amount of hidden layers get set. \n",
    "\n",
    "Then, the weights are initialized to random values at first. \n",
    "\n",
    "After this, forward propogation is performed in order to get the output and the error of the weights. \n",
    "\n",
    "Then after getting the error, you use that to calculate a gradient that is needed in the calculation of the weights to be used in the network. This is done with backwards propogation using the gradient descent algorithm. The weights get adjusted based on the learning rate. \n",
    "\n",
    "After doing all of this, the tensorflow session gets initialized. Once this is done, the neural network can be trained and start making predictions on the speaker data. For every value of a window from the data in the training set, tensorflow runs a session with that and the updates it is receiving from the gradient descent to minimize the cost function. This gets run for every single window in the training data, and the prediction is compared to the labels in the target matrix.\n",
    "\n",
    "Once the predictions are done being made for all of the test data, the average accuracy of the training and test data predictions are calculated, and then printed at the end of every \"epoch\". These few steps are all part of one epoch, and this gets run a designated amount of times. In this case, it was run 100 times. \n",
    "\n",
    "You can see the results of the predictions at the bottom of the page. There is also an image of them included in the project folder. The results steadily improved over time, and appear as if they would continue doing so if given enough time to train the neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, train accuracy = 37.41%, test accuracy = 36.98%\n",
      "Epoch = 2, train accuracy = 45.27%, test accuracy = 44.90%\n",
      "Epoch = 3, train accuracy = 43.77%, test accuracy = 43.31%\n",
      "Epoch = 4, train accuracy = 46.65%, test accuracy = 46.39%\n",
      "Epoch = 5, train accuracy = 46.00%, test accuracy = 46.26%\n",
      "Epoch = 6, train accuracy = 42.97%, test accuracy = 42.06%\n",
      "Epoch = 7, train accuracy = 42.83%, test accuracy = 42.35%\n",
      "Epoch = 8, train accuracy = 47.27%, test accuracy = 46.86%\n",
      "Epoch = 9, train accuracy = 45.68%, test accuracy = 45.42%\n",
      "Epoch = 10, train accuracy = 49.77%, test accuracy = 49.47%\n",
      "Epoch = 11, train accuracy = 45.65%, test accuracy = 45.01%\n",
      "Epoch = 12, train accuracy = 47.59%, test accuracy = 46.98%\n",
      "Epoch = 13, train accuracy = 46.16%, test accuracy = 45.88%\n",
      "Epoch = 14, train accuracy = 49.37%, test accuracy = 49.38%\n",
      "Epoch = 15, train accuracy = 48.41%, test accuracy = 48.15%\n",
      "Epoch = 16, train accuracy = 46.72%, test accuracy = 46.32%\n",
      "Epoch = 17, train accuracy = 48.17%, test accuracy = 47.87%\n",
      "Epoch = 18, train accuracy = 47.59%, test accuracy = 46.56%\n",
      "Epoch = 19, train accuracy = 49.15%, test accuracy = 48.68%\n",
      "Epoch = 20, train accuracy = 45.39%, test accuracy = 45.13%\n",
      "Epoch = 21, train accuracy = 47.87%, test accuracy = 47.66%\n",
      "Epoch = 22, train accuracy = 50.56%, test accuracy = 49.85%\n",
      "Epoch = 23, train accuracy = 50.54%, test accuracy = 50.12%\n",
      "Epoch = 24, train accuracy = 50.36%, test accuracy = 49.51%\n",
      "Epoch = 25, train accuracy = 49.83%, test accuracy = 48.86%\n",
      "Epoch = 26, train accuracy = 45.53%, test accuracy = 44.90%\n",
      "Epoch = 27, train accuracy = 50.29%, test accuracy = 49.43%\n",
      "Epoch = 28, train accuracy = 50.07%, test accuracy = 49.02%\n",
      "Epoch = 29, train accuracy = 49.82%, test accuracy = 48.58%\n",
      "Epoch = 30, train accuracy = 50.13%, test accuracy = 48.65%\n",
      "Epoch = 31, train accuracy = 50.77%, test accuracy = 49.58%\n",
      "Epoch = 32, train accuracy = 51.07%, test accuracy = 49.58%\n",
      "Epoch = 33, train accuracy = 49.93%, test accuracy = 48.77%\n",
      "Epoch = 34, train accuracy = 50.52%, test accuracy = 49.63%\n",
      "Epoch = 35, train accuracy = 49.44%, test accuracy = 48.21%\n",
      "Epoch = 36, train accuracy = 49.52%, test accuracy = 48.89%\n",
      "Epoch = 37, train accuracy = 50.49%, test accuracy = 49.21%\n",
      "Epoch = 38, train accuracy = 51.30%, test accuracy = 50.75%\n",
      "Epoch = 39, train accuracy = 51.07%, test accuracy = 50.72%\n",
      "Epoch = 40, train accuracy = 50.73%, test accuracy = 50.30%\n",
      "Epoch = 41, train accuracy = 51.58%, test accuracy = 50.61%\n",
      "Epoch = 42, train accuracy = 51.73%, test accuracy = 51.28%\n",
      "Epoch = 43, train accuracy = 52.60%, test accuracy = 51.58%\n",
      "Epoch = 44, train accuracy = 52.27%, test accuracy = 51.40%\n",
      "Epoch = 45, train accuracy = 51.90%, test accuracy = 51.21%\n",
      "Epoch = 46, train accuracy = 51.64%, test accuracy = 51.67%\n",
      "Epoch = 47, train accuracy = 52.21%, test accuracy = 51.42%\n",
      "Epoch = 48, train accuracy = 51.04%, test accuracy = 50.67%\n",
      "Epoch = 49, train accuracy = 51.92%, test accuracy = 51.30%\n",
      "Epoch = 50, train accuracy = 52.21%, test accuracy = 51.35%\n",
      "Epoch = 51, train accuracy = 51.57%, test accuracy = 51.33%\n",
      "Epoch = 52, train accuracy = 53.08%, test accuracy = 51.88%\n",
      "Epoch = 53, train accuracy = 52.40%, test accuracy = 51.59%\n",
      "Epoch = 54, train accuracy = 49.84%, test accuracy = 49.50%\n",
      "Epoch = 55, train accuracy = 52.07%, test accuracy = 51.36%\n",
      "Epoch = 56, train accuracy = 50.99%, test accuracy = 50.43%\n",
      "Epoch = 57, train accuracy = 52.60%, test accuracy = 51.63%\n",
      "Epoch = 58, train accuracy = 52.51%, test accuracy = 51.44%\n",
      "Epoch = 59, train accuracy = 52.44%, test accuracy = 51.23%\n",
      "Epoch = 60, train accuracy = 51.45%, test accuracy = 50.57%\n",
      "Epoch = 61, train accuracy = 51.84%, test accuracy = 50.93%\n",
      "Epoch = 62, train accuracy = 52.06%, test accuracy = 51.29%\n",
      "Epoch = 63, train accuracy = 52.24%, test accuracy = 51.14%\n",
      "Epoch = 64, train accuracy = 52.45%, test accuracy = 51.23%\n",
      "Epoch = 65, train accuracy = 52.07%, test accuracy = 51.33%\n",
      "Epoch = 66, train accuracy = 52.17%, test accuracy = 51.58%\n",
      "Epoch = 67, train accuracy = 52.93%, test accuracy = 51.86%\n",
      "Epoch = 68, train accuracy = 53.46%, test accuracy = 52.10%\n",
      "Epoch = 69, train accuracy = 52.69%, test accuracy = 51.68%\n",
      "Epoch = 70, train accuracy = 52.58%, test accuracy = 51.90%\n",
      "Epoch = 71, train accuracy = 52.09%, test accuracy = 50.98%\n",
      "Epoch = 72, train accuracy = 52.76%, test accuracy = 51.87%\n",
      "Epoch = 73, train accuracy = 53.86%, test accuracy = 52.68%\n",
      "Epoch = 74, train accuracy = 53.52%, test accuracy = 52.32%\n",
      "Epoch = 75, train accuracy = 52.58%, test accuracy = 51.64%\n",
      "Epoch = 76, train accuracy = 53.79%, test accuracy = 53.21%\n",
      "Epoch = 77, train accuracy = 51.52%, test accuracy = 50.82%\n",
      "Epoch = 78, train accuracy = 52.77%, test accuracy = 51.72%\n",
      "Epoch = 79, train accuracy = 52.78%, test accuracy = 51.87%\n",
      "Epoch = 80, train accuracy = 52.95%, test accuracy = 52.00%\n",
      "Epoch = 81, train accuracy = 53.13%, test accuracy = 51.77%\n",
      "Epoch = 82, train accuracy = 51.90%, test accuracy = 50.51%\n",
      "Epoch = 83, train accuracy = 52.12%, test accuracy = 51.09%\n",
      "Epoch = 84, train accuracy = 52.51%, test accuracy = 51.81%\n",
      "Epoch = 85, train accuracy = 53.67%, test accuracy = 52.24%\n",
      "Epoch = 86, train accuracy = 52.64%, test accuracy = 51.65%\n",
      "Epoch = 87, train accuracy = 52.92%, test accuracy = 52.00%\n",
      "Epoch = 88, train accuracy = 53.60%, test accuracy = 52.13%\n",
      "Epoch = 89, train accuracy = 51.41%, test accuracy = 50.60%\n",
      "Epoch = 90, train accuracy = 53.46%, test accuracy = 52.51%\n",
      "Epoch = 91, train accuracy = 53.64%, test accuracy = 52.33%\n",
      "Epoch = 92, train accuracy = 53.26%, test accuracy = 52.37%\n",
      "Epoch = 93, train accuracy = 53.59%, test accuracy = 52.27%\n",
      "Epoch = 94, train accuracy = 52.25%, test accuracy = 50.98%\n",
      "Epoch = 95, train accuracy = 53.66%, test accuracy = 52.44%\n",
      "Epoch = 96, train accuracy = 52.65%, test accuracy = 51.57%\n",
      "Epoch = 97, train accuracy = 52.93%, test accuracy = 52.14%\n",
      "Epoch = 98, train accuracy = 51.76%, test accuracy = 50.90%\n",
      "Epoch = 99, train accuracy = 52.62%, test accuracy = 51.11%\n",
      "Epoch = 100, train accuracy = 52.39%, test accuracy = 51.37%\n"
     ]
    }
   ],
   "source": [
    "# Implementation of a simple MLP network with one hidden layer. Tested on the iris data set.\n",
    "# Requires: numpy, sklearn>=0.18.1, tensorflow>=1.0\n",
    "\n",
    "# NOTE: In order to make the code simple, we rewrite x * W_1 + b_1 = x' * W_1'\n",
    "# where x' = [x | 1] and W_1' is the matrix W_1 appended with a new row with elements b_1's.\n",
    "# Similarly, for h * W_2 + b_2\n",
    "\n",
    "# author :vinhkhuc  Feb 26, 2017\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "def init_weights(shape):\n",
    "    \"\"\" Weight initialization \"\"\"\n",
    "    weights = tf.random_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(weights)\n",
    "\n",
    "def forwardprop(X, w_1, w_2):\n",
    "    \"\"\"\n",
    "    Forward-propagation.\n",
    "    IMPORTANT: yhat is not softmax since TensorFlow's softmax_cross_entropy_with_logits() does that internally.\n",
    "    \"\"\"\n",
    "    h    = tf.nn.sigmoid(tf.matmul(X, w_1))  # The \\sigma function\n",
    "    yhat = tf.matmul(h, w_2)  # The \\varphi function\n",
    "    return yhat\n",
    "\n",
    "def get_data():\n",
    "    \"\"\" Read the iris data set and split them into training and test sets \"\"\"\n",
    "    # Prepend the column of 1s for bias\n",
    "    N, M  = data.shape\n",
    "    all_X = np.ones((N, M + 1))\n",
    "    all_X[:, 1:] = data\n",
    "\n",
    "    # Convert into one-hot vectors\n",
    "    num_labels = len(np.unique(target))\n",
    "    all_Y = np.eye(num_labels)[target]  # One liner trick!\n",
    "    return train_test_split(all_X, all_Y, test_size=0.1, random_state=RANDOM_SEED)\n",
    "\n",
    "def main():\n",
    "    train_X, test_X, train_y, test_y = get_data()\n",
    "\n",
    "    # Layer's sizes\n",
    "    x_size = train_X.shape[1]   # Number of input nodes: 4 features and 1 bias\n",
    "    h_size = 20                 # Number of hidden nodes\n",
    "    y_size = train_y.shape[1]   # Number of outcomes (3 iris flowers)\n",
    "\n",
    "    # Symbols\n",
    "    X = tf.placeholder(\"float\", shape=[None, x_size])\n",
    "    y = tf.placeholder(\"float\", shape=[None, y_size])\n",
    "\n",
    "    # Weight initializations\n",
    "    w_1 = init_weights((x_size, h_size))\n",
    "    w_2 = init_weights((h_size, y_size))\n",
    "\n",
    "    # Forward propagation\n",
    "    yhat    = forwardprop(X, w_1, w_2)\n",
    "    predict = tf.argmax(yhat, axis=1)\n",
    "\n",
    "    # Backward propagation\n",
    "    cost    = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=yhat))\n",
    "    updates = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "\n",
    "    # Run SGD\n",
    "    #gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "    sess = tf.Session() # config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(100):\n",
    "        # Train with each example\n",
    "        for i in range(len(train_X)):\n",
    "            sess.run(updates, feed_dict={X: train_X[i: i + 1], y: train_y[i: i + 1]})\n",
    "\n",
    "        train_accuracy = np.mean(np.argmax(train_y, axis=1) ==\n",
    "                                 sess.run(predict, feed_dict={X: train_X, y: train_y}))\n",
    "        test_accuracy  = np.mean(np.argmax(test_y, axis=1) ==\n",
    "                                 sess.run(predict, feed_dict={X: test_X, y: test_y}))\n",
    "\n",
    "        print(\"Epoch = %d, train accuracy = %.2f%%, test accuracy = %.2f%%\"\n",
    "              % (epoch + 1, 100. * train_accuracy, 100. * test_accuracy))\n",
    "\n",
    "    sess.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    \n",
    "# Run this with printing the dataset to see how it is organized. Many rows, each assigned with a target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
